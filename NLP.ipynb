{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngzhankang/finalYearProjectUOB/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4WG19GGjVCN"
      },
      "source": [
        "# FINAL YEAR PROJECT\n",
        "Done by : \n",
        "- P1935785 Ang Yak Hng\n",
        "- P1932964 Teo Swee Hong Winson\n",
        "- P1935727 Ng Zhan Kang\n",
        "- P1935488 Triston Loh\n",
        "- P1935602 Ng Ao Yang\n",
        "\n",
        "Class of DIT/FT/3A/05\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTixCl0Yj3aC"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa-0olzCkDtZ"
      },
      "source": [
        "# 1.Cloning Github To Colab Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_no5sNXlBZ_"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "    <b>ATTENTION:</b> The entire section 1 is dedicated to users who are using google colab to do the entire project. This entire process clones the private repository directly into the temporary google colab workspace. Google colab user are to repeat this same proccess whenever in a new session. Users who do not use colab to do this project CAN OMIT THE ENTIRE SECTION 1. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-ZvXSUPkPBq"
      },
      "source": [
        "### 1.1. Configurating SSH keys for GitHub and Colab connection\n",
        "\n",
        "---\n",
        "\n",
        "This entire section can be omitted if users are not using Google Colab at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH5jhDiOliB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c0269c-e906-4a10-d723-2ef85cd86b38"
      },
      "source": [
        "!ssh-keygen -t rsa -b 4096"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating public/private rsa key pair.\n",
            "Enter file in which to save the key (/root/.ssh/id_rsa): \n",
            "Created directory '/root/.ssh'.\n",
            "Enter passphrase (empty for no passphrase): \n",
            "Enter same passphrase again: \n",
            "Your identification has been saved in /root/.ssh/id_rsa.\n",
            "Your public key has been saved in /root/.ssh/id_rsa.pub.\n",
            "The key fingerprint is:\n",
            "SHA256:+4l8fw8xhGbo0QNsXhXODAPN28sRxtaSiT1U5I3ehDM root@d5ef00415fcc\n",
            "The key's randomart image is:\n",
            "+---[RSA 4096]----+\n",
            "|         .o+o*+Bo|\n",
            "|          o+=B@+o|\n",
            "|         oo.*=E++|\n",
            "|         ..+.+o= |\n",
            "|        S .  .+o.|\n",
            "|         .    oo |\n",
            "|        .     .  |\n",
            "|       . o..  .. |\n",
            "|        o.o... ..|\n",
            "+----[SHA256]-----+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujcbhDqDmqP7"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "    <b>ATTENTION:</b> When prompted for a set of informations such as \"Enter a file in which to save the key...\", please press enter and DO NOT type in anything.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUsKDe9tm0hQ",
        "outputId": "0ed4540d-feef-48b8-db67-fe6ef06a935c"
      },
      "source": [
        "!ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# github.com:22 SSH-2.0-babeld-75007963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc7qLuG1m-9h",
        "outputId": "7d053d08-f199-4e19-ebc0-1c7cdd0431cd"
      },
      "source": [
        "!cat /root/.ssh/id_rsa.pub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC6l/5O2Vgs5I1cLSUAgX659iD/etRVXOEdFYMWIDOHkYokszBMATTQL/5CVXO9I4+o3QuJWXfql1z7hd/eYC218H0JaLNlKxbhVsEhUHhq8c2zvmebqBPutKMcPgEJ2SSWcd99Qucy0pjD+STFFPUOz622YGAzae9m3sgzCyiBHvEnBEGPf7JHmzxQ3DeltsqV9rHC2G5fCO8KNxw7b2jut3rj6/r0z5NwS5igkV/05PMQLywlDF0FRBG+gPD0/UJqtT2zrUaBvWjIu81hyhpe1Ag5z1WSa+zf47p3okviUu974U44b3MoWu4lYEceq9zbtIbgHChh+Gt/xKmxApYMmxl60qyHBXLkhcKpZHnI7F+QgqOphO7xBgsOJEZ2o0pP13h25DIY6ZZ8XFgsqcgGAb+LG5UPCWC9G1S4Gw1k5xul+B3uCMaP+EkcjqmFPYwW54/kFg0GUVkM/oB3TuStQvGhP3Xfi/34wFj4LU8tKK476qtI5rE+JDsRzgGQy6xCbgK0JKAKDWJlbraz2Ai3La1uN2dQudfMq78aK03EOIljb6k1Cak88Rye0lnOUubb53rjswmx1NsroadOdW5/zt5DbSLmOE//mPXV6cpG4/YqrX0q/h5fb8TqN8kF/mcWokZcmf82ISorLMvSu8qkbjYWYBu4P+bTwOOXEuPkLw== root@d5ef00415fcc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSwt6wnDnSjx"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "    <b>ATTENTION:</b> After the key has been generated, please copy the entire key. Navigate to your Github Account > Profile Picture > Settings > SSH and GPG keys > New SSH Keys. Paste the generated key into the blank and lable it for your own convenience.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_rpok3voY8A"
      },
      "source": [
        "### 1.2. Testing SSH keys for GitHub and Colab connection\n",
        "\n",
        "---\n",
        "\n",
        "This entire section can be omitted if users are not using Google Colab at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYEnWGicnnC0",
        "outputId": "1e5ac907-d4be-46ad-f1bf-0e329ac4b98c"
      },
      "source": [
        "!ssh -T git@github.com"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Permanently added the RSA host key for IP address '140.82.121.4' to the list of known hosts.\r\n",
            "Hi ngzhankang! You've successfully authenticated, but GitHub does not provide shell access.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gtHa7l8ID8u"
      },
      "source": [
        "### 1.3. Clone Private Repository\n",
        "\n",
        "---\n",
        "\n",
        "This entire section can be omitted if users are not using Google Colab at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7c65FyJIEXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8176ba-b8a9-4105-e557-463187204d8a"
      },
      "source": [
        "!git clone git@github.com:ngzhankang/finalYearProjectUOB.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'finalYearProjectUOB'...\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.121.3' to the list of known hosts.\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 79 (delta 24), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (79/79), 1.03 MiB | 1.10 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpQsykkUqHOB"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D74lUe_QF3kh"
      },
      "source": [
        "# 2.Data Importing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VbDZ5ymKTR6"
      },
      "source": [
        "### 2.1. Load the libraries\n",
        "\n",
        "---\n",
        "\n",
        "Load the necessary libraries for usage in the entire project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMBiWwY8sBBl",
        "outputId": "0994b632-41ad-4d3a-c361-fb0564f069d4"
      },
      "source": [
        "! nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FacXEFOsC04"
      },
      "source": [
        "### 2.2. Check CUDA Version\n",
        "\n",
        "---\n",
        "\n",
        "We need to check the cuda version to download the correct version of spaCy for this application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_20qw2UohOC"
      },
      "source": [
        "# suppress future warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EldCY0t9v2uV",
        "outputId": "3a776f19-85a9-498c-aab2-38d0c7295fed"
      },
      "source": [
        "# install necessary libraries that might not be found\n",
        "!pip install -U spacy\n",
        "!python -m spacy validate\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy[cuda110,transformers,lookups]\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "# check versions of libraries we are going to use\n",
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import tensorflow\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import spacy\n",
        "import platform\n",
        "\n",
        "message=\"        Versions        \"\n",
        "print(\"*\"*len(message))\n",
        "print(message)\n",
        "print(\"*\"*len(message))\n",
        "print(\"Tensorflow version={}\".format(tensorflow.__version__))\n",
        "print(\"Keras version={}\".format(tensorflow.keras.__version__))\n",
        "print(\"Sklearn version={}\".format(sklearn.__version__))\n",
        "print(\"Numpy version={}\".format(np.__version__))\n",
        "print(\"Pandas version={}\".format(pd.__version__))\n",
        "print(\"Seaborn version={}\".format(sns.__version__))\n",
        "print(\"Matplotlib version={}\".format(matplotlib.__version__))\n",
        "print(\"SpaCy version={}\".format(spacy.__version__))\n",
        "print(\"Python version={}\".format(platform.python_version()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 12.0MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Collecting pathy>=0.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0a/52ae1c659fc08f13dd7c0ae07b88e4f807ad83fb9954a59b0b0a3d1a8ab6/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 54.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting thinc<8.1.0,>=8.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 59.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=8e6957afe69dd649316548653ca9281c3c94f7b41f02ba594c50ccbd3954db97\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built smart-open\n",
            "Installing collected packages: catalogue, typer, smart-open, pathy, srsly, pydantic, thinc, spacy-legacy, spacy\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: smart-open 5.0.0\n",
            "    Uninstalling smart-open-5.0.0:\n",
            "      Successfully uninstalled smart-open-5.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 pathy-0.5.2 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n",
            "2021-05-07 10:04:01.820113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "================= Installed pipeline packages (spaCy v3.0.6) =================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.7/dist-packages/spacy\u001b[0m\n",
            "\n",
            "No pipeline packages found in your current environment.\n",
            "\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/6f/43037c7bcc8bd8ba7c9074256b1a11596daa15555808ec748048c1507f08/pip-21.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 16.2MB/s \n",
            "\u001b[?25hCollecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/1b/7012b145cb228aed20f9b2b8b259df49e7963d900799ea44791f54d06ab9/setuptools-56.1.0-py3-none-any.whl (785kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 22.1MB/s \n",
            "\u001b[?25hRequirement already up-to-date: wheel in /usr/local/lib/python3.7/dist-packages (0.36.2)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pip, setuptools\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "  Found existing installation: setuptools 56.0.0\n",
            "    Uninstalling setuptools-56.0.0:\n",
            "      Successfully uninstalled setuptools-56.0.0\n",
            "Successfully installed pip-21.1.1 setuptools-56.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy[cuda110,lookups,transformers] in /usr/local/lib/python3.7/dist-packages (3.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (2.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (56.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (3.0.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (2.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (3.7.4.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (2.0.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (1.19.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (0.5.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (8.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (1.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (20.9)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (1.7.3)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (0.3.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda110,lookups,transformers]) (0.4.1)\n",
            "Collecting spacy-lookups-data<1.1.0,>=1.0.0\n",
            "  Downloading spacy_lookups_data-1.0.0-py2.py3-none-any.whl (93.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 93.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting spacy-transformers<1.1.0,>=1.0.1\n",
            "  Downloading spacy_transformers-1.0.2-py2.py3-none-any.whl (39 kB)\n",
            "Collecting cupy-cuda110<9.0.0,>=5.0.0b4\n",
            "  Downloading cupy_cuda110-8.6.0-cp37-cp37m-manylinux1_x86_64.whl (165.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 165.3 MB 44 kB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy[cuda110,lookups,transformers]) (3.4.1)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.7/dist-packages (from cupy-cuda110<9.0.0,>=5.0.0b4->spacy[cuda110,lookups,transformers]) (0.6)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy[cuda110,lookups,transformers]) (2.4.7)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy[cuda110,lookups,transformers]) (3.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda110,lookups,transformers]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda110,lookups,transformers]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda110,lookups,transformers]) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda110,lookups,transformers]) (3.0.4)\n",
            "Collecting transformers<4.6.0,>=3.4.0\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 70.4 MB/s \n",
            "\u001b[?25hCollecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.8.3-cp37-cp37m-manylinux2014_x86_64.whl (998 kB)\n",
            "\u001b[K     |████████████████████████████████| 998 kB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.1.0,>=1.0.1->spacy[cuda110,lookups,transformers]) (1.8.1+cu101)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.6.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[cuda110,lookups,transformers]) (3.10.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.6.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[cuda110,lookups,transformers]) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.6.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[cuda110,lookups,transformers]) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 72.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy[cuda110,lookups,transformers]) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy[cuda110,lookups,transformers]) (1.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.6.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[cuda110,lookups,transformers]) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.6.0,>=3.4.0->spacy-transformers<1.1.0,>=1.0.1->spacy[cuda110,lookups,transformers]) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, spacy-alignments, spacy-transformers, spacy-lookups-data, cupy-cuda110\n",
            "Successfully installed cupy-cuda110-8.6.0 sacremoses-0.0.45 spacy-alignments-0.8.3 spacy-lookups-data-1.0.0 spacy-transformers-1.0.2 tokenizers-0.10.2 transformers-4.5.1\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "2021-05-07 10:04:38.915775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting en-core-web-lg==3.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.0.0/en_core_web_lg-3.0.0-py3-none-any.whl (778.8 MB)\n",
            "\u001b[K     |█████████████████████████▍      | 619.1 MB 1.3 MB/s eta 0:02:06"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leKoAEG_KWf8"
      },
      "source": [
        "### 2.3. Load the modules\n",
        "\n",
        "---\n",
        "\n",
        "Load the necessary modules for usage in the entire project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U04wypEUv2p1"
      },
      "source": [
        "# importing necessary modules for this project\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import string\n",
        "import spacy\n",
        "\n",
        "# activate the GPU to run spaCy with GPU\n",
        "spacy.prefer_gpu()\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca1X-gSJKap_"
      },
      "source": [
        "### 2.4. Load the dataset\n",
        "\n",
        "---\n",
        "\n",
        "Load the dataset for usage in the entire project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owSKzElwKdh1"
      },
      "source": [
        "# use pandas to read the excel file and populate it in a pandas dataframe\n",
        "companies = pd.read_excel('./Cleaned Dataset1.xlsx')\n",
        "\n",
        "# see the top 10 companies that are populated in the dataframe\n",
        "companies.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TI1D_-KP6hC"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qKHTDyOP9bz"
      },
      "source": [
        "# 3.Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8p50I8GQCAg"
      },
      "source": [
        "### 3.1. Get overview of dataset\n",
        "\n",
        "---\n",
        "\n",
        "Get statistical information of the dataset to understand the dataset better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iea82R6Dm2J"
      },
      "source": [
        "# see the row headers of the entire pandas dataframe first\n",
        "list(companies.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVX1CBSTLZqm"
      },
      "source": [
        "# get the total number of records in the dataframe\n",
        "df_count = companies['Company_ID'].count()\n",
        "\n",
        "# get count of unique contries where companies are based in\n",
        "df_countCountry = companies['Country'].nunique()\n",
        "\n",
        "# get count of total unique sectors where companies are from\n",
        "df_countSector = companies['Sector'].nunique()\n",
        "\n",
        "# get count of total unique subseector where companies are from\n",
        "df_countsubSector = companies['Subsector'].nunique()\n",
        "\n",
        "# get count of total unique valuechain where companies are from\n",
        "df_countValuechain = companies['Valuechain'].nunique()\n",
        "\n",
        "print('Total number of records:', df_count)\n",
        "print('Total number of countries:', df_countCountry)\n",
        "print('Total number of sectors:', df_countSector)\n",
        "print('Total number of subsectors:', df_countsubSector)\n",
        "print('Total number of valuechain:', df_countValuechain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1C_l7ytUixQ"
      },
      "source": [
        "# get total number of countries\n",
        "df_totalCountries = companies['Country'].value_counts()\n",
        "\n",
        "# get list of unique sector\n",
        "df_sector = companies['Sector'].value_counts()\n",
        "\n",
        "# get list of unique archetype\n",
        "df_archetype = companies['Archetype'].value_counts()\n",
        "\n",
        "# get list of unique valuechain\n",
        "df_valuechain = companies['Valuechain'].value_counts()\n",
        "\n",
        "print('List of unique countries:\\n{}'.format(df_totalCountries))\n",
        "print()\n",
        "print('List of unique sector:\\n{}'.format(df_sector))\n",
        "print()\n",
        "print('List of unique valuechain:\\n{}'.format(df_valuechain))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIoXot6HWEWP"
      },
      "source": [
        "# get list of unique subsector\n",
        "df_subsector = companies['Subsector'].value_counts()\n",
        "\n",
        "print('List of unique Subsector:\\n{}'.format(df_subsector))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjaNooD3Uz3c"
      },
      "source": [
        "print('List of unique archetype:\\n{}'.format(df_archetype))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57EHaR92D9UP"
      },
      "source": [
        "### 3.2. Drop unncessary columns\n",
        "\n",
        "---\n",
        "\n",
        "Here, we will drop columns that wiill not aid in our EDA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC9-PuS6EDXT"
      },
      "source": [
        "# declare the list of the row names that are redundant\n",
        "rows_to_drop = ['Company_ID', 'PIC', 'Websites', 'Remarks']\n",
        "\n",
        "# use a conditional expression to filter out those rows\n",
        "df_filteredCompanies = companies.drop(labels=rows_to_drop, axis=1)\n",
        "\n",
        "df_filteredCompanies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3S6ZQzySmC0"
      },
      "source": [
        "### 3.3. Filter rows with valid data\n",
        "\n",
        "---\n",
        "\n",
        "Extract columns with Nan values and list them out here. Afterwards, gather the rows deemed suitable to process NLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZLoO_4SSry7"
      },
      "source": [
        "# find all the rows with nan data in sector, subsector, archetype and valuechain\n",
        "cols_to_check = ['Sector', 'Subsector', 'Archetype', 'Valuechain', 'Company Profile Information']\n",
        "empty = df_filteredCompanies[df_filteredCompanies[cols_to_check].isnull().all(1)]\n",
        "\n",
        "empty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrQjbN7uStmr"
      },
      "source": [
        "# now we get the dataset that are valid\n",
        "df_valid = pd.concat([df_filteredCompanies, empty, empty]).drop_duplicates(keep=False)\n",
        "\n",
        "df_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuYZkLS8fkjV"
      },
      "source": [
        "# now we check the count of the total filtered dataset again\n",
        "df_filterCount = df_valid['Company'].count()\n",
        "\n",
        "print('Total number of filtered records:', df_filterCount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf69nqOrWr_b"
      },
      "source": [
        "### 3.4. Get graphical overview of dataset\n",
        "\n",
        "---\n",
        "\n",
        "Get visualised information of the dataset to understand the dataset better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRLIFECVS1os"
      },
      "source": [
        "sns.set_style('darkgrid')\n",
        "plt_dims = (30, 13)\n",
        "fig, ax = plt.subplots(figsize=plt_dims)\n",
        "\n",
        "# plot a barplot to see number of companies that belongs to specific sectors\n",
        "sns.countplot(x=\"Sector\", data=df_valid, ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EyLs8d1TfSw"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>Analysis Summary:</b> We see that most of the companies comes from the CNI(Construction And Infrastructure), with TMT(Technology, Media and Telecomm) sector.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwMqcB0MStbJ"
      },
      "source": [
        "# Pie chart\n",
        "labels = list(df_valid['Country'].unique())\n",
        "sizes = list(df_valid['Country'].value_counts())\n",
        "\n",
        "plt_dims = (30, 13)\n",
        "fig1, ax1 = plt.subplots(figsize=plt_dims)\n",
        "ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "# Equal aspect ratio ensures that pie is drawn as a circle\n",
        "ax1.axis('equal')  \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A73dge-zZhSD"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>Analysis Summary:</b> We see that most of the companies are Singapre-Based companies, followed up by Hong Kong, Indonesia and so on.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3bMDdQTfTnX"
      },
      "source": [
        "### 3.5. See examples of company description\n",
        "\n",
        "---\n",
        "\n",
        "We would now like to see some examples of the company descriptions in order to undestand later how to preprocess them later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBQ4Ml5gfkg7"
      },
      "source": [
        "# configurate pandas dataframe to let us see the entire company description IN FULL\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# get the 1st 50 results and observe\n",
        "df_valid.loc[0:49,'Company Profile Information']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x50UFKzNkezP"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>Analysis Summary:</b> We do realise that some of the company profile message have some breaks in between like '\\n'. Now, we will have to take away all these problems so that it is one string of paragraph with no such annotations in betweeen.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETEpM1eCk9Cf"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0rub1v2k-dq"
      },
      "source": [
        "# 4.Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxCABlrVlDW6"
      },
      "source": [
        "### 4.1. Removing `\\n`\n",
        "\n",
        "---\n",
        "\n",
        "Now, we will like to standardize all the paragraphs such that the are homogenous, before we tokenize the paragraph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAq4hq6XlMBp"
      },
      "source": [
        "# get rid of the \\n found in the respective descriptions\n",
        "df_valid = df_valid.replace('\\n',' ', regex=True)\n",
        "\n",
        "# now we validate to see if theye are really gone\n",
        "df_valid.loc[0:49,'Company Profile Information']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UbMqS2dvXeZ"
      },
      "source": [
        "### 4.2. Calculating the word length distribution\n",
        "\n",
        "---\n",
        "\n",
        "Here, we will be calculating the world length distribution of the collective company description."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDsrjeimvDl8"
      },
      "source": [
        "# first, add in a new column that tabluates the length of the respecive company description\n",
        "df_valid[\"length\"] = df_valid[\"Company Profile Information\"].str.len()\n",
        "df_valid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "725S9NxvyZXQ"
      },
      "source": [
        "# now plot a distribution plot to see the word length distribution\n",
        "sns.distplot(df_valid[\"length\"], kde=True)\n",
        "plt.title('Word Length Distribution')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjI1Z5ogyl6h"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>Analysis Summary:</b> We can see that there is a high record of the company description having a total word length of around 200 to 300, while those aboce 800 is very rare.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPgyXL60rqg"
      },
      "source": [
        "### 4.3. Subsample from the entire dataset\n",
        "\n",
        "---\n",
        "\n",
        "We will now subsample a part of the dataset from the entire dataset. This is important as firstly, we need to ensure that our tokenization is working correctly in a smaller scale dataset, since using the entire dataset to do it will be very time consuming."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC9h-jIM07v2"
      },
      "source": [
        "# declare sample size here first (CHANGE IT AS THE TRAINING DATA INCREASES)\n",
        "sample_size = 350\n",
        "\n",
        "# now we will get the data from the restricted range of sample size\n",
        "subsample = df_valid[:sample_size]\n",
        "subsample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2q_t5v3SSq2"
      },
      "source": [
        "### 4.4. Populating Nan cells\n",
        "\n",
        "---\n",
        "\n",
        "We will now have to populate Nan cells with space so that we can carry on and process with text tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAUWZOuMSP7O"
      },
      "source": [
        "# fill na with space instead of others\n",
        "df_valid.fillna(\" \" ,inplace=True)\n",
        "df_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvaDZUtsVIYk"
      },
      "source": [
        "### 4.5. Assigning tags\n",
        "---\n",
        "In this section, we will be assigning tags to every row, so that we can make use of the given keywords for bag-of-words (BoW) processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMryE61_3L3d"
      },
      "source": [
        "# Programmatically assign tags to each definition\n",
        "sector_keywords = pd.read_excel('./sector_master_definition.xlsx')\n",
        "df_keywords = sector_keywords[['Sector', 'Subsector', 'Archetype', 'Value Chain', 'Sector Keywords']]\n",
        "\n",
        "# capitalise all tags\n",
        "df_keywords['Value Chain'] = df_keywords['Value Chain'].str.upper()\n",
        "df_keywords.fillna(' ', inplace=True)\n",
        "df_keywords['Sector Keywords'] = df_keywords['Sector Keywords'].str.upper()\n",
        "df_keywords['Sector Keywords'].replace(' ', '[]', inplace=True)\n",
        "\n",
        "# save unique tags, sorted for consistency across runs\n",
        "sector = np.sort(df_keywords['Sector'].unique())\n",
        "subsector = np.sort(df_keywords['Subsector'].unique())\n",
        "archetype = np.sort(df_keywords['Archetype'].unique())\n",
        "valuechain = np.sort(df_keywords['Value Chain'].unique())\n",
        "print(len(sector), len(subsector), len(archetype), len(valuechain))\n",
        "tag_counts = [len(sector), len(subsector), len(archetype), len(valuechain)]\n",
        "\n",
        "# assign number tag list to each row\n",
        "taglist = []\n",
        "for index, row in df_keywords.iterrows():\n",
        "    temp = []\n",
        "\n",
        "    temp.append(np.where(sector == row['Sector'])[0][0])\n",
        "    temp.append(np.where(subsector == row['Subsector'])[0][0])\n",
        "    temp.append(np.where(archetype == row['Archetype'])[0][0])\n",
        "    temp.append(np.where(valuechain == row['Value Chain'])[0][0])\n",
        "\n",
        "    taglist.append(temp)\n",
        "\n",
        "# assign completed taglist to column in dataframe\n",
        "df_keywords['list_tag'] = taglist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeY7nEgNAL5n"
      },
      "source": [
        "# process data for homogenity\n",
        "df_valid['Valuechain'] = df_valid['Valuechain'].str.split().str.join(' ')\n",
        "df_valid['Valuechain'] = df_valid['Valuechain'].str.upper()\n",
        "df_valid['Sector'] = df_valid['Sector'].str.upper()\n",
        "df_valid['Valuechain'].replace('', ' ', inplace=True)\n",
        "\n",
        "taglist_df = []\n",
        "# process tags for records\n",
        "for index, row in df_valid.iterrows():\n",
        "    temp = []\n",
        "\n",
        "    temp.append(np.where(sector == row['Sector'])[0][0])\n",
        "    temp.append(np.where(subsector == row['Subsector'])[0][0])\n",
        "    temp.append(np.where(archetype == row['Archetype'])[0][0])\n",
        "    temp.append(np.where(valuechain == row['Valuechain'])[0][0])\n",
        "\n",
        "    taglist_df.append(temp)\n",
        "\n",
        "df_valid['list_tag'] = taglist_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMQVBNOGz4cn"
      },
      "source": [
        "### 4.6. Text Tokenization, Removing Stop Words, punctuations, numbers, stop words and Lower Case\n",
        "\n",
        "---\n",
        "\n",
        "Now we will start to tokenize the word after we have ensure that the text description between the company descriptions are homogenous. In this process, we will also process with stop words, punctuations, numeric figures, lower cap words and lemmatize words all using the spaCy API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM-Q_-iEUgFQ"
      },
      "source": [
        "# we will have to ensure all the dtype of the respective columns are in string and not float for spacy to handle properly, so now we will attempt to convert all into strings\n",
        "columns_to_convert = ['Sector', 'Subsector', 'Archetype', 'Valuechain', 'Company Profile Information']\n",
        "\n",
        "for i in columns_to_convert:\n",
        "  df_valid[i] = df_valid[i].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihIc0sUPPu_A"
      },
      "source": [
        "Here we will do everything necessary to start up spacy for use in preprocessing the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf-9naDFAIZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b3321f-026a-4aa4-ff02-033e2f7ddb7a"
      },
      "source": [
        "# import required libraries \n",
        "from spacy.language import Language\n",
        "from spacy.tokens import Doc\n",
        "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER, CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
        "from spacy.util import compile_infix_regex\n",
        "\n",
        "# initialise nlp engine\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# declare custom properties\n",
        "Doc.set_extension('processed', default=True, force=True)\n",
        "Doc.set_extension('word_bag', default=True, force=True)\n",
        "\n",
        "# Modify tokenizer infix patterns\n",
        "infixes = (\n",
        "    LIST_ELLIPSES\n",
        "    + LIST_ICONS\n",
        "    + [\n",
        "        r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
        "        r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n",
        "            al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
        "        ),\n",
        "        r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
        "        r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
        "    ]\n",
        ")\n",
        "\n",
        "infix_re = compile_infix_regex(infixes)\n",
        "nlp.tokenizer.infix_finditer = infix_re.finditer\n",
        "\n",
        "# custom lemmatizer\n",
        "@Language.component(\"custom_preprocess\")\n",
        "def custom_preprocess(doc):\n",
        "    temp = []\n",
        "\n",
        "    # filter through each token and add to preprocessed text if requirements #\n",
        "    # met.                                                                   #\n",
        "    for t in doc:\n",
        "        if (not t.is_punct and not t.like_num and not t.is_stop and not t.is_digit and not (t.ent_type == 396 or t.ent_type == 397)):\n",
        "            temp.append(t.lemma_.upper())\n",
        "\n",
        "    doc._.processed = temp\n",
        "\n",
        "    return doc\n",
        "\n",
        "# custom BoW processor\n",
        "@Language.component('BoW')\n",
        "def bag_of_words(doc):\n",
        "    pass\n",
        "\n",
        "# add custom pipeline components to default pipeline\n",
        "nlp.add_pipe('custom_preprocess', last=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.custom_preprocess>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13bwIYewPsD9"
      },
      "source": [
        "# run the pipeline on data\n",
        "processed_doc = list(nlp.pipe(df_valid['Company Profile Information']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UaWgX5lZStt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ea171d2-4591-41a4-a4fa-3cad17d2d139"
      },
      "source": [
        "# add lemmatised words to dataframe\n",
        "df_valid['processed'] = [doc._.processed for doc in processed_doc]\n",
        "\n",
        "df_valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Country</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Subsector</th>\n",
              "      <th>Archetype</th>\n",
              "      <th>Valuechain</th>\n",
              "      <th>Company Profile Information</th>\n",
              "      <th>length</th>\n",
              "      <th>list_tag</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CUBIC DECO PTE. LTD.</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>CNI</td>\n",
              "      <td>cni_service providers</td>\n",
              "      <td>cni_service providers</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>Cubic Deco Pte Ltd is an interior contractor based in Singapore. Incorporated in March 2005 and with a current strength of 30, we provide professional services for interior fit out and construction works for residential, offices and retail spaces. We also offer a complete custom-made carpentry and joinery works right here at our inhouse workshop.</td>\n",
              "      <td>349</td>\n",
              "      <td>[1, 6, 14, 5]</td>\n",
              "      <td>[CUBIC, DECO, PTE, LTD, INTERIOR, CONTRACTOR, BASE, SINGAPORE, INCORPORATE, MARCH, CURRENT, STRENGTH, PROVIDE, PROFESSIONAL, SERVICE, INTERIOR, FIT, CONSTRUCTION, WORK, RESIDENTIAL, OFFICE, RETAIL, SPACE, OFFER, COMPLETE, CUSTOM-MADE, CARPENTRY, JOINERY, WORK, RIGHT, INHOUSE, WORKSHOP]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UTRACON CORPORATION PTE. LTD.</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>CNI</td>\n",
              "      <td>buildings &amp; industrial</td>\n",
              "      <td>buildings &amp; industrial_contractor</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>The Company provides civil engineering services and on-site post-tensioning products.</td>\n",
              "      <td>85</td>\n",
              "      <td>[1, 4, 10, 5]</td>\n",
              "      <td>[COMPANY, PROVIDE, CIVIL, ENGINEERING, SERVICE, ON-SITE, POST-TENSIONING, PRODUCT]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GUANGDONG OVERLAND CERAMICS CO., LTD</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>CNI</td>\n",
              "      <td>building material</td>\n",
              "      <td>building material_manufacturer</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>Overland Ceramics is a ceramic tile manufacturer &amp; supplier integrating design, research and development, manufacturing and marketing. Our products are wholesale marble tile &amp; stone tile.</td>\n",
              "      <td>187</td>\n",
              "      <td>[1, 3, 8, 5]</td>\n",
              "      <td>[OVERLAND, CERAMICS, CERAMIC, TILE, MANUFACTURER, SUPPLIER, INTEGRATE, DESIGN, RESEARCH, DEVELOPMENT, MANUFACTURING, MARKETING, PRODUCT, WHOLESALE, MARBLE, TILE, STONE, TILE]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BYMA PTE LTD</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>CNI</td>\n",
              "      <td>buildings &amp; industrial</td>\n",
              "      <td>buildings &amp; industrial_contractor</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>BYMA is a joint-venture between Bouygues Batiment International and SPA Project Management. The company brings together the expertise of a leading international construction group (Bouygues Construction) and the local knowledge of Yoma Strategic Holdings focusing on the Myanmar market. In April 2013, BYMA was awarded by Thanlin Estate Development the design and build contract for the 2nd phase of Star City (Zone B), a prominent residential estate featuring 4,980 apartments, car parks and communal facilities located along the Bago River in the outskirts of Yangon. In December 2014, BYMA was also awarded the 3rd phase of Star City (Zone C). The development will be composed of 6 residential towers, including 956 residential units, as well as a 26,000m2 car park, located around the periphery of the site over two levels, providing 1,147 car park spaces. With more than 1,500 employees, BYMA will soon be the leading construction company in Myanmar.</td>\n",
              "      <td>956</td>\n",
              "      <td>[1, 4, 10, 5]</td>\n",
              "      <td>[BYMA, JOINT-VENTURE, BOUYGUES, BATIMENT, INTERNATIONAL, SPA, PROJECT, MANAGEMENT, COMPANY, BRING, EXPERTISE, LEAD, INTERNATIONAL, CONSTRUCTION, GROUP, BOUYGUES, CONSTRUCTION, LOCAL, KNOWLEDGE, YOMA, STRATEGIC, HOLDINGS, FOCUS, MYANMAR, MARKET, APRIL, BYMA, AWARD, THANLIN, ESTATE, DEVELOPMENT, DESIGN, BUILD, CONTRACT, PHASE, STAR, CITY, ZONE, B, PROMINENT, RESIDENTIAL, ESTATE, FEATURE, APARTMENT, CAR, PARK, COMMUNAL, FACILITY, LOCATE, BAGO, RIVER, OUTSKIRT, YANGON, DECEMBER, BYMA, AWARD, PHASE, STAR, CITY, ZONE, C, DEVELOPMENT, COMPOSE, RESIDENTIAL, TOWER, INCLUDE, RESIDENTIAL, UNIT, CAR, PARK, LOCATE, PERIPHERY, SITE, LEVEL, PROVIDE, CAR, PARK, SPACE, EMPLOYEE, BYMA, SOON, LEAD, CONSTRUCTION, COMPANY, MYANMAR]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TTCL MALAYSIA SDN. BHD.</td>\n",
              "      <td>MALAYSIA</td>\n",
              "      <td>CNI</td>\n",
              "      <td>buildings &amp; industrial</td>\n",
              "      <td>buildings &amp; industrial_contractor</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>TTCL has experiences and expertises in providing integrated design and engineering, procurement of machinery &amp; equipment, and construction (Integrated EPC) of turnkey projects for industrial and process plants, mainly in energy, petrochemical, chemical and power industries.</td>\n",
              "      <td>274</td>\n",
              "      <td>[1, 4, 10, 5]</td>\n",
              "      <td>[TTCL, EXPERIENCE, EXPERTISE, PROVIDE, INTEGRATED, DESIGN, ENGINEERING, PROCUREMENT, MACHINERY, EQUIPMENT, CONSTRUCTION, INTEGRATED, EPC, TURNKEY, PROJECT, INDUSTRIAL, PROCESS, PLANT, MAINLY, ENERGY, PETROCHEMICAL, CHEMICAL, POWER, INDUSTRY]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>OGX NETWORKS SDN. BHD.</td>\n",
              "      <td>MALAYSIA</td>\n",
              "      <td>TMT</td>\n",
              "      <td>it services</td>\n",
              "      <td>it services</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>Our company specializes in IT Enterprise Distribution and Services. We mainly focus on IT Networking, Wireless Networking, Networking Security and Data Center Implementation.</td>\n",
              "      <td>174</td>\n",
              "      <td>[6, 17, 46, 5]</td>\n",
              "      <td>[COMPANY, SPECIALIZE, ENTERPRISE, DISTRIBUTION, SERVICES,  , MAINLY, FOCUS, NETWORKING, WIRELESS, NETWORKING, NETWORKING, SECURITY, DATA, CENTER, IMPLEMENTATION]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>ASCENT AUTO MALAYSIA SDN. BHD.</td>\n",
              "      <td>MALAYSIA</td>\n",
              "      <td>TMT</td>\n",
              "      <td>consumer electronics</td>\n",
              "      <td>consumer electronics_distributor</td>\n",
              "      <td>DOWNSTREAM</td>\n",
              "      <td>WHOLESALE OF ELECTRICAL AND ELECTRONICS GOODS</td>\n",
              "      <td>45</td>\n",
              "      <td>[6, 8, 20, 3]</td>\n",
              "      <td>[WHOLESALE, ELECTRICAL, ELECTRONICS, GOOD]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>VELOX DIGITAL SINGAPORE PTE. LTD.</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>TMT</td>\n",
              "      <td>digital_business</td>\n",
              "      <td>digital_business</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>Gojek is Southeast Asia’s leading on-demand, multi-service tech platform providing access to a wide range of services including transport, payments, food delivery, logistics, and many more.</td>\n",
              "      <td>189</td>\n",
              "      <td>[6, 9, 24, 5]</td>\n",
              "      <td>[GOJEK, SOUTHEAST, ASIA, LEAD, ON-DEMAND, MULTI-SERVICE, TECH, PLATFORM, PROVIDE, ACCESS, WIDE, RANGE, SERVICE, INCLUDE, TRANSPORT, PAYMENT, FOOD, DELIVERY, LOGISTICS]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>TRANSAM INDUSTRIES PTE LTD</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>OOS</td>\n",
              "      <td>others</td>\n",
              "      <td>others</td>\n",
              "      <td></td>\n",
              "      <td>We specialise in the production of Thermal Transfer Ribbon (TTR), Coding Ribbon for flexible packaging and Ribbons for Magnetic Ink Character Recognition (MICR).</td>\n",
              "      <td>161</td>\n",
              "      <td>[4, 24, 64, 0]</td>\n",
              "      <td>[SPECIALISE, PRODUCTION, THERMAL, TRANSFER, RIBBON, TTR, CODE, RIBBON, FLEXIBLE, PACKAGING, RIBBONS, MAGNETIC, INK, CHARACTER, RECOGNITION, MICR]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>HEROLEADS (THAILAND) CO.,LTD.</td>\n",
              "      <td>THAILAND</td>\n",
              "      <td>TMT</td>\n",
              "      <td>media</td>\n",
              "      <td>advertisement &amp; marketing agency</td>\n",
              "      <td>DOWNSTREAM</td>\n",
              "      <td>We are Southeast Asia's leading independent performance marketing agency. We work with companies across the region to unleash the power of digital and enable sustainable business growth - at scale.</td>\n",
              "      <td>197</td>\n",
              "      <td>[6, 18, 0, 3]</td>\n",
              "      <td>[SOUTHEAST, ASIA, LEADING, INDEPENDENT, PERFORMANCE, MARKETING, AGENCY, WORK, COMPANY, REGION, UNLEASH, POWER, DIGITAL, ENABLE, SUSTAINABLE, BUSINESS, GROWTH, SCALE]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>507 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Company  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         processed\n",
              "0                    CUBIC DECO PTE. LTD.  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                    [CUBIC, DECO, PTE, LTD, INTERIOR, CONTRACTOR, BASE, SINGAPORE, INCORPORATE, MARCH, CURRENT, STRENGTH, PROVIDE, PROFESSIONAL, SERVICE, INTERIOR, FIT, CONSTRUCTION, WORK, RESIDENTIAL, OFFICE, RETAIL, SPACE, OFFER, COMPLETE, CUSTOM-MADE, CARPENTRY, JOINERY, WORK, RIGHT, INHOUSE, WORKSHOP]\n",
              "1           UTRACON CORPORATION PTE. LTD.  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [COMPANY, PROVIDE, CIVIL, ENGINEERING, SERVICE, ON-SITE, POST-TENSIONING, PRODUCT]\n",
              "2    GUANGDONG OVERLAND CERAMICS CO., LTD  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [OVERLAND, CERAMICS, CERAMIC, TILE, MANUFACTURER, SUPPLIER, INTEGRATE, DESIGN, RESEARCH, DEVELOPMENT, MANUFACTURING, MARKETING, PRODUCT, WHOLESALE, MARBLE, TILE, STONE, TILE]\n",
              "3                            BYMA PTE LTD  ...  [BYMA, JOINT-VENTURE, BOUYGUES, BATIMENT, INTERNATIONAL, SPA, PROJECT, MANAGEMENT, COMPANY, BRING, EXPERTISE, LEAD, INTERNATIONAL, CONSTRUCTION, GROUP, BOUYGUES, CONSTRUCTION, LOCAL, KNOWLEDGE, YOMA, STRATEGIC, HOLDINGS, FOCUS, MYANMAR, MARKET, APRIL, BYMA, AWARD, THANLIN, ESTATE, DEVELOPMENT, DESIGN, BUILD, CONTRACT, PHASE, STAR, CITY, ZONE, B, PROMINENT, RESIDENTIAL, ESTATE, FEATURE, APARTMENT, CAR, PARK, COMMUNAL, FACILITY, LOCATE, BAGO, RIVER, OUTSKIRT, YANGON, DECEMBER, BYMA, AWARD, PHASE, STAR, CITY, ZONE, C, DEVELOPMENT, COMPOSE, RESIDENTIAL, TOWER, INCLUDE, RESIDENTIAL, UNIT, CAR, PARK, LOCATE, PERIPHERY, SITE, LEVEL, PROVIDE, CAR, PARK, SPACE, EMPLOYEE, BYMA, SOON, LEAD, CONSTRUCTION, COMPANY, MYANMAR]\n",
              "4                 TTCL MALAYSIA SDN. BHD.  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [TTCL, EXPERIENCE, EXPERTISE, PROVIDE, INTEGRATED, DESIGN, ENGINEERING, PROCUREMENT, MACHINERY, EQUIPMENT, CONSTRUCTION, INTEGRATED, EPC, TURNKEY, PROJECT, INDUSTRIAL, PROCESS, PLANT, MAINLY, ENERGY, PETROCHEMICAL, CHEMICAL, POWER, INDUSTRY]\n",
              "..                                    ...  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...\n",
              "514                OGX NETWORKS SDN. BHD.  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [COMPANY, SPECIALIZE, ENTERPRISE, DISTRIBUTION, SERVICES,  , MAINLY, FOCUS, NETWORKING, WIRELESS, NETWORKING, NETWORKING, SECURITY, DATA, CENTER, IMPLEMENTATION]\n",
              "515        ASCENT AUTO MALAYSIA SDN. BHD.  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [WHOLESALE, ELECTRICAL, ELECTRONICS, GOOD]\n",
              "516     VELOX DIGITAL SINGAPORE PTE. LTD.  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [GOJEK, SOUTHEAST, ASIA, LEAD, ON-DEMAND, MULTI-SERVICE, TECH, PLATFORM, PROVIDE, ACCESS, WIDE, RANGE, SERVICE, INCLUDE, TRANSPORT, PAYMENT, FOOD, DELIVERY, LOGISTICS]\n",
              "517            TRANSAM INDUSTRIES PTE LTD  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [SPECIALISE, PRODUCTION, THERMAL, TRANSFER, RIBBON, TTR, CODE, RIBBON, FLEXIBLE, PACKAGING, RIBBONS, MAGNETIC, INK, CHARACTER, RECOGNITION, MICR]\n",
              "518         HEROLEADS (THAILAND) CO.,LTD.  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [SOUTHEAST, ASIA, LEADING, INDEPENDENT, PERFORMANCE, MARKETING, AGENCY, WORK, COMPANY, REGION, UNLEASH, POWER, DIGITAL, ENABLE, SUSTAINABLE, BUSINESS, GROWTH, SCALE]\n",
              "\n",
              "[507 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNrfPLrEbXSh"
      },
      "source": [
        "### 4.7. Bag of Words / TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1zJBkfx6euk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e23661-84fb-41b9-a72b-8e8a933cb5a8"
      },
      "source": [
        "# combine all keywords from all sectors\n",
        "keywords_masterlist = []\n",
        "for index, row in df_keywords.iterrows():\n",
        "    keywords_masterlist += eval(row['Sector Keywords'])\n",
        "\n",
        "# remove extraenous keywords, then sort\n",
        "keywords_masterlist = sorted(list(set(keywords_masterlist)))\n",
        "print(len(keywords_masterlist))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyzmOri2ZrGl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62acddb3-7d88-47b9-8afd-bca637df82c7"
      },
      "source": [
        "# do bag of words\n",
        "bow_vectors = []\n",
        "for index, row in df_valid.iterrows():\n",
        "    company = row['processed']\n",
        "\n",
        "    dictionary = dict.fromkeys(keywords_masterlist, 0)\n",
        "    for word in company:\n",
        "        if word in keywords_masterlist:\n",
        "            dictionary[word] += 1\n",
        "\n",
        "    # append to dataframe\n",
        "    bow_vectors.append(list(dictionary.values()))\n",
        "\n",
        "    # print(f'{sum(dictionary.values()):>3}/{len(dictionary.values()):<3} |', dictionary.values())\n",
        "\n",
        "df_valid['BoW_vectors'] = bow_vectors\n",
        "\n",
        "df_valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Country</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Subsector</th>\n",
              "      <th>Archetype</th>\n",
              "      <th>Valuechain</th>\n",
              "      <th>Company Profile Information</th>\n",
              "      <th>length</th>\n",
              "      <th>list_tag</th>\n",
              "      <th>processed</th>\n",
              "      <th>BoW_vectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CUBIC DECO PTE. LTD.</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>CNI</td>\n",
              "      <td>cni_service providers</td>\n",
              "      <td>cni_service providers</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>Cubic Deco Pte Ltd is an interior contractor based in Singapore. Incorporated in March 2005 and with a current strength of 30, we provide professional services for interior fit out and construction works for residential, offices and retail spaces. We also offer a complete custom-made carpentry and joinery works right here at our inhouse workshop.</td>\n",
              "      <td>349</td>\n",
              "      <td>[1, 6, 14, 5]</td>\n",
              "      <td>[CUBIC, DECO, PTE, LTD, INTERIOR, CONTRACTOR, BASE, SINGAPORE, INCORPORATE, MARCH, CURRENT, STRENGTH, PROVIDE, PROFESSIONAL, SERVICE, INTERIOR, FIT, CONSTRUCTION, WORK, RESIDENTIAL, OFFICE, RETAIL, SPACE, OFFER, COMPLETE, CUSTOM-MADE, CARPENTRY, JOINERY, WORK, RIGHT, INHOUSE, WORKSHOP]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UTRACON CORPORATION PTE. LTD.</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>CNI</td>\n",
              "      <td>buildings &amp; industrial</td>\n",
              "      <td>buildings &amp; industrial_contractor</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>The Company provides civil engineering services and on-site post-tensioning products.</td>\n",
              "      <td>85</td>\n",
              "      <td>[1, 4, 10, 5]</td>\n",
              "      <td>[COMPANY, PROVIDE, CIVIL, ENGINEERING, SERVICE, ON-SITE, POST-TENSIONING, PRODUCT]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GUANGDONG OVERLAND CERAMICS CO., LTD</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>CNI</td>\n",
              "      <td>building material</td>\n",
              "      <td>building material_manufacturer</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>Overland Ceramics is a ceramic tile manufacturer &amp; supplier integrating design, research and development, manufacturing and marketing. Our products are wholesale marble tile &amp; stone tile.</td>\n",
              "      <td>187</td>\n",
              "      <td>[1, 3, 8, 5]</td>\n",
              "      <td>[OVERLAND, CERAMICS, CERAMIC, TILE, MANUFACTURER, SUPPLIER, INTEGRATE, DESIGN, RESEARCH, DEVELOPMENT, MANUFACTURING, MARKETING, PRODUCT, WHOLESALE, MARBLE, TILE, STONE, TILE]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BYMA PTE LTD</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>CNI</td>\n",
              "      <td>buildings &amp; industrial</td>\n",
              "      <td>buildings &amp; industrial_contractor</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>BYMA is a joint-venture between Bouygues Batiment International and SPA Project Management. The company brings together the expertise of a leading international construction group (Bouygues Construction) and the local knowledge of Yoma Strategic Holdings focusing on the Myanmar market. In April 2013, BYMA was awarded by Thanlin Estate Development the design and build contract for the 2nd phase of Star City (Zone B), a prominent residential estate featuring 4,980 apartments, car parks and communal facilities located along the Bago River in the outskirts of Yangon. In December 2014, BYMA was also awarded the 3rd phase of Star City (Zone C). The development will be composed of 6 residential towers, including 956 residential units, as well as a 26,000m2 car park, located around the periphery of the site over two levels, providing 1,147 car park spaces. With more than 1,500 employees, BYMA will soon be the leading construction company in Myanmar.</td>\n",
              "      <td>956</td>\n",
              "      <td>[1, 4, 10, 5]</td>\n",
              "      <td>[BYMA, JOINT-VENTURE, BOUYGUES, BATIMENT, INTERNATIONAL, SPA, PROJECT, MANAGEMENT, COMPANY, BRING, EXPERTISE, LEAD, INTERNATIONAL, CONSTRUCTION, GROUP, BOUYGUES, CONSTRUCTION, LOCAL, KNOWLEDGE, YOMA, STRATEGIC, HOLDINGS, FOCUS, MYANMAR, MARKET, APRIL, BYMA, AWARD, THANLIN, ESTATE, DEVELOPMENT, DESIGN, BUILD, CONTRACT, PHASE, STAR, CITY, ZONE, B, PROMINENT, RESIDENTIAL, ESTATE, FEATURE, APARTMENT, CAR, PARK, COMMUNAL, FACILITY, LOCATE, BAGO, RIVER, OUTSKIRT, YANGON, DECEMBER, BYMA, AWARD, PHASE, STAR, CITY, ZONE, C, DEVELOPMENT, COMPOSE, RESIDENTIAL, TOWER, INCLUDE, RESIDENTIAL, UNIT, CAR, PARK, LOCATE, PERIPHERY, SITE, LEVEL, PROVIDE, CAR, PARK, SPACE, EMPLOYEE, BYMA, SOON, LEAD, CONSTRUCTION, COMPANY, MYANMAR]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TTCL MALAYSIA SDN. BHD.</td>\n",
              "      <td>MALAYSIA</td>\n",
              "      <td>CNI</td>\n",
              "      <td>buildings &amp; industrial</td>\n",
              "      <td>buildings &amp; industrial_contractor</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>TTCL has experiences and expertises in providing integrated design and engineering, procurement of machinery &amp; equipment, and construction (Integrated EPC) of turnkey projects for industrial and process plants, mainly in energy, petrochemical, chemical and power industries.</td>\n",
              "      <td>274</td>\n",
              "      <td>[1, 4, 10, 5]</td>\n",
              "      <td>[TTCL, EXPERIENCE, EXPERTISE, PROVIDE, INTEGRATED, DESIGN, ENGINEERING, PROCUREMENT, MACHINERY, EQUIPMENT, CONSTRUCTION, INTEGRATED, EPC, TURNKEY, PROJECT, INDUSTRIAL, PROCESS, PLANT, MAINLY, ENERGY, PETROCHEMICAL, CHEMICAL, POWER, INDUSTRY]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>KPAC INTERTRADE CO.,LTD.</td>\n",
              "      <td>THAILAND</td>\n",
              "      <td>REH</td>\n",
              "      <td>residential</td>\n",
              "      <td>residential_integrated player</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>Business, trading, renting houses, buildings, land and other real estate.</td>\n",
              "      <td>73</td>\n",
              "      <td>[5, 26, 76, 5]</td>\n",
              "      <td>[BUSINESS, TRADING, RENT, HOUSE, BUILDING, LAND, REAL, ESTATE]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>ASCENT AUTO MALAYSIA SDN. BHD.</td>\n",
              "      <td>MALAYSIA</td>\n",
              "      <td>TMT</td>\n",
              "      <td>consumer electronics</td>\n",
              "      <td>consumer electronics_distributor</td>\n",
              "      <td>DOWNSTREAM</td>\n",
              "      <td>WHOLESALE OF ELECTRICAL AND ELECTRONICS GOODS</td>\n",
              "      <td>45</td>\n",
              "      <td>[6, 8, 20, 3]</td>\n",
              "      <td>[WHOLESALE, ELECTRICAL, ELECTRONICS, GOOD]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>VELOX DIGITAL SINGAPORE PTE. LTD.</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>TMT</td>\n",
              "      <td>digital_business</td>\n",
              "      <td>digital_business</td>\n",
              "      <td>MIDSTREAM</td>\n",
              "      <td>Gojek is Southeast Asia’s leading on-demand, multi-service tech platform providing access to a wide range of services including transport, payments, food delivery, logistics, and many more.</td>\n",
              "      <td>189</td>\n",
              "      <td>[6, 9, 24, 5]</td>\n",
              "      <td>[GOJEK, SOUTHEAST, ASIA, LEAD, ON-DEMAND, MULTI-SERVICE, TECH, PLATFORM, PROVIDE, ACCESS, WIDE, RANGE, SERVICE, INCLUDE, TRANSPORT, PAYMENT, FOOD, DELIVERY, LOGISTICS]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>TRANSAM INDUSTRIES PTE LTD</td>\n",
              "      <td>SINGAPORE</td>\n",
              "      <td>OOS</td>\n",
              "      <td>others</td>\n",
              "      <td>others</td>\n",
              "      <td></td>\n",
              "      <td>We specialise in the production of Thermal Transfer Ribbon (TTR), Coding Ribbon for flexible packaging and Ribbons for Magnetic Ink Character Recognition (MICR).</td>\n",
              "      <td>161</td>\n",
              "      <td>[4, 24, 64, 0]</td>\n",
              "      <td>[SPECIALISE, PRODUCTION, THERMAL, TRANSFER, RIBBON, TTR, CODE, RIBBON, FLEXIBLE, PACKAGING, RIBBONS, MAGNETIC, INK, CHARACTER, RECOGNITION, MICR]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>HEROLEADS (THAILAND) CO.,LTD.</td>\n",
              "      <td>THAILAND</td>\n",
              "      <td>TMT</td>\n",
              "      <td>media</td>\n",
              "      <td>advertisement &amp; marketing agency</td>\n",
              "      <td>DOWNSTREAM</td>\n",
              "      <td>We are Southeast Asia's leading independent performance marketing agency. We work with companies across the region to unleash the power of digital and enable sustainable business growth - at scale.</td>\n",
              "      <td>197</td>\n",
              "      <td>[6, 18, 0, 3]</td>\n",
              "      <td>[SOUTHEAST, ASIA, LEADING, INDEPENDENT, PERFORMANCE, MARKETING, AGENCY, WORK, COMPANY, REGION, UNLEASH, POWER, DIGITAL, ENABLE, SUSTAINABLE, BUSINESS, GROWTH, SCALE]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>407 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Company  ...                                                                                                                                                                                                                                                                                                        BoW_vectors\n",
              "0                    CUBIC DECO PTE. LTD.  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "1           UTRACON CORPORATION PTE. LTD.  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "2    GUANGDONG OVERLAND CERAMICS CO., LTD  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "3                            BYMA PTE LTD  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "4                 TTCL MALAYSIA SDN. BHD.  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "..                                    ...  ...                                                                                                                                                                                                                                                                                                                ...\n",
              "513              KPAC INTERTRADE CO.,LTD.  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "515        ASCENT AUTO MALAYSIA SDN. BHD.  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "516     VELOX DIGITAL SINGAPORE PTE. LTD.  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "517            TRANSAM INDUSTRIES PTE LTD  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "518         HEROLEADS (THAILAND) CO.,LTD.  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n",
              "\n",
              "[407 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GynU6j-bLgdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aaa3af7-ede8-4b45-be20-1e611c0436dc"
      },
      "source": [
        "# clean up BoW data \n",
        "temp = 0\n",
        "for index, row in df_valid.iterrows():\n",
        "    if sum(row['BoW_vectors']) < 1:\n",
        "        df_valid.drop(index, inplace=True)\n",
        "\n",
        "df_valid.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(407, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXPxFhqqgX9f"
      },
      "source": [
        "# 5.Models\n",
        "---\n",
        "Here we will train the model that will help categorize each company."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhjAJFR4NOq9"
      },
      "source": [
        "### 5.1. Training Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi2lRa6pgWtj",
        "outputId": "58158517-525c-4189-e10a-fc82b567ab18"
      },
      "source": [
        "import keras\n",
        "\n",
        "print('--- Version Checking ---')\n",
        "print(\"Keras:\", keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Version Checking ---\n",
            "Keras: 2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il4Tp6FBlYSR"
      },
      "source": [
        "# split datasets to train and test\n",
        "df_train = df_valid.iloc[:330]\n",
        "df_test = df_valid.iloc[330:]\n",
        "\n",
        "df_train.fillna(0, inplace=True)\n",
        "df_test.fillna(0, inplace=True)\n",
        "\n",
        "X_train = np.array(list(df_train['BoW_vectors']))\n",
        "y_train = np.array(list(df_train['list_tag']))\n",
        "\n",
        "X_test = np.array(list(df_test['BoW_vectors']))\n",
        "y_test = np.array(list(df_test['list_tag']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KRBNPh0hHTY"
      },
      "source": [
        "# create model\n",
        "from keras.layers import Dense\n",
        "from keras import Sequential\n",
        "\n",
        "def create_model(name, input_dim, output_dim):\n",
        "    model = Sequential(name=name)\n",
        "\n",
        "    # hidden layers\n",
        "    model.add(Dense(input_dim, kernel_initializer='normal', activation='relu', input_dim=input_dim))\n",
        "    model.add(Dense(input_dim // 2, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(input_dim // 4, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(input_dim // 8, kernel_initializer='normal', activation='relu'))\n",
        "\n",
        "    # output\n",
        "    model.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "# one hot \n",
        "def one_hot(arr, n_cat):\n",
        "    output = []\n",
        "    for n in arr:\n",
        "        result = np.zeros(n_cat)\n",
        "        result[n] = 1\n",
        "\n",
        "        output.append(result)\n",
        "\n",
        "    return np.array(output, dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvGIYGxlAetm",
        "outputId": "bd8d3fe6-a74b-4716-df33-d14fe97efd76"
      },
      "source": [
        "print(one_hot(y_train[:,0], len(sector)).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(330, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD219eVw8uGS",
        "outputId": "7d497452-8f79-4e6f-e7d2-2aa604ac2f1e"
      },
      "source": [
        "sector_model = create_model('sector_model', len(keywords_masterlist), len(sector))\n",
        "subsector_model = create_model('subsector_model', len(keywords_masterlist), len(subsector))\n",
        "archetype_model = create_model('archetype_model', len(keywords_masterlist), len(archetype))\n",
        "valuechain_model = create_model('valuechain_model', len(keywords_masterlist), len(valuechain))\n",
        "\n",
        "models = [sector_model, subsector_model, archetype_model, valuechain_model]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sector_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_110 (Dense)            (None, 1473)              2171202   \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 736)               1084864   \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 368)               271216    \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 184)               67896     \n",
            "_________________________________________________________________\n",
            "dense_114 (Dense)            (None, 7)                 1295      \n",
            "=================================================================\n",
            "Total params: 3,596,473\n",
            "Trainable params: 3,596,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"subsector_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_115 (Dense)            (None, 1473)              2171202   \n",
            "_________________________________________________________________\n",
            "dense_116 (Dense)            (None, 736)               1084864   \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 368)               271216    \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 184)               67896     \n",
            "_________________________________________________________________\n",
            "dense_119 (Dense)            (None, 32)                5920      \n",
            "=================================================================\n",
            "Total params: 3,601,098\n",
            "Trainable params: 3,601,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"archetype_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_120 (Dense)            (None, 1473)              2171202   \n",
            "_________________________________________________________________\n",
            "dense_121 (Dense)            (None, 736)               1084864   \n",
            "_________________________________________________________________\n",
            "dense_122 (Dense)            (None, 368)               271216    \n",
            "_________________________________________________________________\n",
            "dense_123 (Dense)            (None, 184)               67896     \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 92)                17020     \n",
            "=================================================================\n",
            "Total params: 3,612,198\n",
            "Trainable params: 3,612,198\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"valuechain_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_125 (Dense)            (None, 1473)              2171202   \n",
            "_________________________________________________________________\n",
            "dense_126 (Dense)            (None, 736)               1084864   \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 368)               271216    \n",
            "_________________________________________________________________\n",
            "dense_128 (Dense)            (None, 184)               67896     \n",
            "_________________________________________________________________\n",
            "dense_129 (Dense)            (None, 9)                 1665      \n",
            "=================================================================\n",
            "Total params: 3,596,843\n",
            "Trainable params: 3,596,843\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq8R0cZXEwUK",
        "outputId": "e83c9b2f-08a3-4a00-c88b-a1c0568ea597"
      },
      "source": [
        "for i in range(4):\n",
        "    models[i].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    models[i].fit(X_train, one_hot(y_train[:,i], tag_counts[i]), epochs=200, batch_size=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 6ms/step - loss: 1.3207 - accuracy: 0.5714\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.8692\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.9004\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1508 - accuracy: 0.9608\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2245 - accuracy: 0.9320\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1627 - accuracy: 0.9448\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 0.9788\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9759\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9657\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1327 - accuracy: 0.9475\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9732\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9694\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9704\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0944 - accuracy: 0.9656\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.9753\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9737\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0778 - accuracy: 0.9749\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9793\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9641\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0777 - accuracy: 0.9809\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0653 - accuracy: 0.9840\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0657 - accuracy: 0.9767\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9741\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9695\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.9777\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.9750\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9596\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.9780\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9886\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9716\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.9828\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9861\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9588\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9784\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9794\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0774 - accuracy: 0.9637\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9643\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9733\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9821\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9691\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.9555\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0592 - accuracy: 0.9754\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9790\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9732\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9648\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.9440\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9678\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1895 - accuracy: 0.9343\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1522 - accuracy: 0.9485\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.9722\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1478 - accuracy: 0.9470\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.9712\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9612\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9771\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 0.9700\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9754\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9802\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9668\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9692\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9755\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9810\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0540 - accuracy: 0.9772\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9685\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.9785\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0499 - accuracy: 0.9861\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.9537\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9808\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9737\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9799\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.9764\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0822 - accuracy: 0.9729\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0803 - accuracy: 0.9595\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0624 - accuracy: 0.9729\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9622\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9616\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9710\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9653\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9638\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0627 - accuracy: 0.9701\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9791\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.9781\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9748\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9660\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9558\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9791\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9709\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0646 - accuracy: 0.9722\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9709\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9707\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1005 - accuracy: 0.9627\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9679\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9839\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.9722\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9804\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9810\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9714\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0566 - accuracy: 0.9750\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9674\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0629 - accuracy: 0.9698\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9648\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9796\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9834\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0557 - accuracy: 0.9788\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9786\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9633\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9620\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9628\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0936 - accuracy: 0.9548\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9769\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9869\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9698\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9868\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.9455\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9781\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0635 - accuracy: 0.9734\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0955 - accuracy: 0.9583\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9814\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9632\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0677 - accuracy: 0.9737\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9630\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0593 - accuracy: 0.9732\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9790\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9570\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9620\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.9763\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.9721\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0628 - accuracy: 0.9717\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0483 - accuracy: 0.9844\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9645\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0578 - accuracy: 0.9768\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9789\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9709\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9777\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0592 - accuracy: 0.9717\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9703\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0729 - accuracy: 0.9664\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9572\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9580\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9742\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9740\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.9565\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0536 - accuracy: 0.9798\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9744\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.9793\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9756\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9692\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9816\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9574\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0563 - accuracy: 0.9792\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0653 - accuracy: 0.9725\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9720\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.9761\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9804\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9713\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9666\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9848\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.9762\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0546 - accuracy: 0.9775\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0520 - accuracy: 0.9730\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9664\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0585 - accuracy: 0.9796\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9700\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0547 - accuracy: 0.9812\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9748\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9584\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9694\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.9761\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.9788\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9715\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9673\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9730\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9798\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9858\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.9711\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0707 - accuracy: 0.9683\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9804\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9605\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0693 - accuracy: 0.9725\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9636\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9630\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9667\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 0.9713\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9868\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9766\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0807 - accuracy: 0.9768\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9745\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9710\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0457 - accuracy: 0.9843\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9793\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9722\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.9730\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9588\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9795\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9715\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9739\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.9756\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9870\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0642 - accuracy: 0.9746\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9688\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0573 - accuracy: 0.9758\n",
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 8ms/step - loss: 2.9859 - accuracy: 0.2724\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.4470 - accuracy: 0.6433\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.9729 - accuracy: 0.7550\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6582 - accuracy: 0.8401\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.6085 - accuracy: 0.8305\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4487 - accuracy: 0.8430\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.8709\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.8704\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.8319\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3214 - accuracy: 0.9014\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3403 - accuracy: 0.8988\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8903\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2922 - accuracy: 0.9106\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3192 - accuracy: 0.9054\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2930 - accuracy: 0.9094\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3426 - accuracy: 0.8740\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8800\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2717 - accuracy: 0.9058\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2319 - accuracy: 0.9156\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2530 - accuracy: 0.9157\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1927 - accuracy: 0.9319\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2483 - accuracy: 0.8920\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1990 - accuracy: 0.9336\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.8900\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3077 - accuracy: 0.8844\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2473 - accuracy: 0.9138\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2219 - accuracy: 0.9063\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2036 - accuracy: 0.9302\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2196 - accuracy: 0.9021\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2171 - accuracy: 0.9058\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2651 - accuracy: 0.8988\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1908 - accuracy: 0.9328\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2090 - accuracy: 0.9345\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2291 - accuracy: 0.9101\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2833 - accuracy: 0.9034\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1491 - accuracy: 0.9492\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1921 - accuracy: 0.9329\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2144 - accuracy: 0.9100\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2219 - accuracy: 0.9259\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2552 - accuracy: 0.9069\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1885 - accuracy: 0.9339\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1838 - accuracy: 0.9435\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2954 - accuracy: 0.8837\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1856 - accuracy: 0.9264\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2040 - accuracy: 0.9207\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2178 - accuracy: 0.9195\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1752 - accuracy: 0.9327\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1920 - accuracy: 0.9327\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2022 - accuracy: 0.9156\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.8976\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2213 - accuracy: 0.9143\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2063 - accuracy: 0.9174\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2488 - accuracy: 0.8918\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1798 - accuracy: 0.9182\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1586 - accuracy: 0.9223\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2165 - accuracy: 0.9041\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1631 - accuracy: 0.9543\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2073 - accuracy: 0.8966\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2493 - accuracy: 0.9021\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2100 - accuracy: 0.9131\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2403 - accuracy: 0.9032\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1872 - accuracy: 0.9299\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2355 - accuracy: 0.9007\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2116 - accuracy: 0.9188\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1915 - accuracy: 0.9288\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1840 - accuracy: 0.9217\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1944 - accuracy: 0.9239\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2028 - accuracy: 0.9094\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1853 - accuracy: 0.9241\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2029 - accuracy: 0.9217\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2111 - accuracy: 0.9033\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1923 - accuracy: 0.9173\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1923 - accuracy: 0.9210\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1934 - accuracy: 0.9155\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1625 - accuracy: 0.9397\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1795 - accuracy: 0.9361\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2192 - accuracy: 0.9197\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1667 - accuracy: 0.9257\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2035 - accuracy: 0.9229\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1658 - accuracy: 0.9329\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1921 - accuracy: 0.9184\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1870 - accuracy: 0.9163\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2072 - accuracy: 0.9128\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2159 - accuracy: 0.9150\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1928 - accuracy: 0.9251\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1862 - accuracy: 0.9115\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1765 - accuracy: 0.9219\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1748 - accuracy: 0.9201\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1811 - accuracy: 0.9151\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2099 - accuracy: 0.9244\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2117 - accuracy: 0.9236\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1920 - accuracy: 0.9206\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1962 - accuracy: 0.9205\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1865 - accuracy: 0.9247\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1856 - accuracy: 0.9247\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1776 - accuracy: 0.9198\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2083 - accuracy: 0.9186\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2122 - accuracy: 0.9207\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2007 - accuracy: 0.9039\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1349 - accuracy: 0.9451\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2013 - accuracy: 0.9119\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1703 - accuracy: 0.9219\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2004 - accuracy: 0.9196\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2094 - accuracy: 0.9226\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1811 - accuracy: 0.9303\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3188 - accuracy: 0.8927\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2523 - accuracy: 0.8955\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2516 - accuracy: 0.9129\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4529 - accuracy: 0.8335\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4516 - accuracy: 0.8657\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2645 - accuracy: 0.9211\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2382 - accuracy: 0.9110\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2453 - accuracy: 0.9099\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1858 - accuracy: 0.9226\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2003 - accuracy: 0.9140\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1585 - accuracy: 0.9315\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2091 - accuracy: 0.9014\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1816 - accuracy: 0.9170\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1822 - accuracy: 0.9236\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1996 - accuracy: 0.9262\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1774 - accuracy: 0.9085\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2075 - accuracy: 0.9192\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2241 - accuracy: 0.8939\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1893 - accuracy: 0.9311\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1875 - accuracy: 0.9212\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1882 - accuracy: 0.9262\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1570 - accuracy: 0.9268\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1783 - accuracy: 0.9218\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1509 - accuracy: 0.9304\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1805 - accuracy: 0.9289\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1934 - accuracy: 0.9207\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2211 - accuracy: 0.8981\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1710 - accuracy: 0.9308\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1697 - accuracy: 0.9281\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1698 - accuracy: 0.9153\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2162 - accuracy: 0.9154\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1735 - accuracy: 0.9331\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2123 - accuracy: 0.9188\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1764 - accuracy: 0.9244\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1709 - accuracy: 0.9277\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2060 - accuracy: 0.9072\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2482 - accuracy: 0.9053\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1526 - accuracy: 0.9427\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2260 - accuracy: 0.9099\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1996 - accuracy: 0.9317\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1871 - accuracy: 0.9305\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2014 - accuracy: 0.9227\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1653 - accuracy: 0.9322\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1731 - accuracy: 0.9090\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1721 - accuracy: 0.9304\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.9294\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1577 - accuracy: 0.9255\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1589 - accuracy: 0.9415\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1799 - accuracy: 0.9361\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1808 - accuracy: 0.9207\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1872 - accuracy: 0.9023\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1661 - accuracy: 0.9255\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1845 - accuracy: 0.9093\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1968 - accuracy: 0.9219\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1985 - accuracy: 0.9123\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1778 - accuracy: 0.9264\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1655 - accuracy: 0.9250\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1897 - accuracy: 0.9161\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1899 - accuracy: 0.9132\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1740 - accuracy: 0.9197\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1969 - accuracy: 0.9224\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2098 - accuracy: 0.9217\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1747 - accuracy: 0.9364\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2185 - accuracy: 0.9097\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2266 - accuracy: 0.9187\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2310 - accuracy: 0.9204\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1926 - accuracy: 0.9322\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1771 - accuracy: 0.9225\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1918 - accuracy: 0.9251\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1695 - accuracy: 0.9289\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1862 - accuracy: 0.9014\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1772 - accuracy: 0.9152\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1573 - accuracy: 0.9373\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.9327\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1720 - accuracy: 0.9247\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1772 - accuracy: 0.9308\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1776 - accuracy: 0.9245\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2086 - accuracy: 0.9238\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1804 - accuracy: 0.9310\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1987 - accuracy: 0.9104\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1856 - accuracy: 0.9177\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1776 - accuracy: 0.9389\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1713 - accuracy: 0.9227\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1884 - accuracy: 0.9351\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1931 - accuracy: 0.9188\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2109 - accuracy: 0.9192\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1758 - accuracy: 0.9347\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2193 - accuracy: 0.9030\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1949 - accuracy: 0.9184\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1464 - accuracy: 0.9419\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2393 - accuracy: 0.9022\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2217 - accuracy: 0.9106\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1806 - accuracy: 0.9309\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1783 - accuracy: 0.9231\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2015 - accuracy: 0.9167\n",
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 7ms/step - loss: 3.9470 - accuracy: 0.2578\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 2.1773 - accuracy: 0.5500\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.5917 - accuracy: 0.5937\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.2385 - accuracy: 0.6970\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.8961 - accuracy: 0.7762\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.8072\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.6184 - accuracy: 0.8350\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5523 - accuracy: 0.8480\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4860 - accuracy: 0.8851\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4492 - accuracy: 0.8738\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8845\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.8801\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.8610\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.8437\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8661\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.8871\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.8711\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3384 - accuracy: 0.8969\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3227 - accuracy: 0.8713\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2924 - accuracy: 0.9067\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3395 - accuracy: 0.8836\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8366\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8975\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3446 - accuracy: 0.8956\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3320 - accuracy: 0.8804\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2947 - accuracy: 0.8986\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3415 - accuracy: 0.8807\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8430\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3387 - accuracy: 0.8893\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2935 - accuracy: 0.8845\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3560 - accuracy: 0.8560\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3166 - accuracy: 0.8898\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2734 - accuracy: 0.9164\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2378 - accuracy: 0.9298\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3047 - accuracy: 0.8915\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3179 - accuracy: 0.8861\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2771 - accuracy: 0.9156\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2423 - accuracy: 0.9125\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3210 - accuracy: 0.8879\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2869 - accuracy: 0.8972\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3245 - accuracy: 0.8967\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2837 - accuracy: 0.8955\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2438 - accuracy: 0.9082\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2624 - accuracy: 0.8952\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3098 - accuracy: 0.8866\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2158 - accuracy: 0.9111\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2991 - accuracy: 0.8834\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2717 - accuracy: 0.9059\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2782 - accuracy: 0.8913\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2390 - accuracy: 0.8899\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2644 - accuracy: 0.9009\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2963 - accuracy: 0.8909\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2368 - accuracy: 0.9048\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2070 - accuracy: 0.9291\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2496 - accuracy: 0.9119\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2917 - accuracy: 0.8885\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2455 - accuracy: 0.9088\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2490 - accuracy: 0.9069\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2227 - accuracy: 0.9187\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2483 - accuracy: 0.9030\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2290 - accuracy: 0.9144\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2415 - accuracy: 0.9169\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2733 - accuracy: 0.8960\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2901 - accuracy: 0.8925\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2746 - accuracy: 0.8848\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2450 - accuracy: 0.9030\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2535 - accuracy: 0.8838\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2443 - accuracy: 0.9016\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2252 - accuracy: 0.9065\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2537 - accuracy: 0.8954\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2865 - accuracy: 0.8809\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3014 - accuracy: 0.8807\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2715 - accuracy: 0.8994\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2169 - accuracy: 0.9122\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2923 - accuracy: 0.8768\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2895 - accuracy: 0.8800\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2693 - accuracy: 0.8795\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2140 - accuracy: 0.9076\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2864 - accuracy: 0.8786\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2322 - accuracy: 0.9170\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2249 - accuracy: 0.9164\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3452 - accuracy: 0.8856\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2618 - accuracy: 0.9076\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2996 - accuracy: 0.8974\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2833 - accuracy: 0.8943\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2116 - accuracy: 0.9252\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3352 - accuracy: 0.8741\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2582 - accuracy: 0.8900\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2316 - accuracy: 0.9114\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2669 - accuracy: 0.8957\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2607 - accuracy: 0.9084\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2457 - accuracy: 0.8781\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2563 - accuracy: 0.9064\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2326 - accuracy: 0.9016\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2451 - accuracy: 0.8941\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2664 - accuracy: 0.8789\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2203 - accuracy: 0.9069\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2270 - accuracy: 0.9067\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2193 - accuracy: 0.8979\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2171 - accuracy: 0.9112\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2209 - accuracy: 0.9190\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2645 - accuracy: 0.8929\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2587 - accuracy: 0.9019\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2781 - accuracy: 0.8924\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2719 - accuracy: 0.8870\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1885 - accuracy: 0.9199\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.9072\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2589 - accuracy: 0.8919\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2518 - accuracy: 0.8897\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2105 - accuracy: 0.9105\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2713 - accuracy: 0.9052\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2209 - accuracy: 0.9160\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2521 - accuracy: 0.8937\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2324 - accuracy: 0.9079\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2511 - accuracy: 0.8948\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2637 - accuracy: 0.8768\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2236 - accuracy: 0.9077\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2935 - accuracy: 0.8848\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2384 - accuracy: 0.9062\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2155 - accuracy: 0.9186\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2740 - accuracy: 0.8860\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2316 - accuracy: 0.9190\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2377 - accuracy: 0.9054\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2954 - accuracy: 0.8778\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2706 - accuracy: 0.8989\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.8855\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2764 - accuracy: 0.8785\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1771 - accuracy: 0.9366\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1994 - accuracy: 0.9295\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1968 - accuracy: 0.9285\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2784 - accuracy: 0.8962\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2411 - accuracy: 0.9150\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2145 - accuracy: 0.9053\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1757 - accuracy: 0.9348\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1767 - accuracy: 0.9441\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2478 - accuracy: 0.8942\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2259 - accuracy: 0.9011\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2299 - accuracy: 0.8984\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2193 - accuracy: 0.9145\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2861 - accuracy: 0.8804\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2374 - accuracy: 0.9083\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2788 - accuracy: 0.8777\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2460 - accuracy: 0.9084\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2215 - accuracy: 0.9201\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2513 - accuracy: 0.8830\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2300 - accuracy: 0.8874\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1946 - accuracy: 0.9241\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2015 - accuracy: 0.9196\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2586 - accuracy: 0.8977\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2257 - accuracy: 0.9103\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2719 - accuracy: 0.8780\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2469 - accuracy: 0.9116\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2644 - accuracy: 0.8933\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2222 - accuracy: 0.9134\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1955 - accuracy: 0.9231\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2045 - accuracy: 0.9219\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2379 - accuracy: 0.9027\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2041 - accuracy: 0.9087\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2617 - accuracy: 0.8967\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2418 - accuracy: 0.9076\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2381 - accuracy: 0.9046\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2437 - accuracy: 0.8842\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2006 - accuracy: 0.9241\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2215 - accuracy: 0.9099\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1929 - accuracy: 0.9218\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2187 - accuracy: 0.9188\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2660 - accuracy: 0.8954\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2431 - accuracy: 0.9110\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2949 - accuracy: 0.8587\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2643 - accuracy: 0.8887\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2306 - accuracy: 0.8874\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2275 - accuracy: 0.9063\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2307 - accuracy: 0.9226\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2445 - accuracy: 0.8862\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2550 - accuracy: 0.8738\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2686 - accuracy: 0.8839\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2513 - accuracy: 0.9054\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2837 - accuracy: 0.8914\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.3108 - accuracy: 0.8827\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.7504 - accuracy: 0.8527\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.7908 - accuracy: 0.7635\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.5976 - accuracy: 0.8484\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4829 - accuracy: 0.8457\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8542\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2994 - accuracy: 0.8944\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2726 - accuracy: 0.8899\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.9059\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2677 - accuracy: 0.9005\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2635 - accuracy: 0.9117\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2293 - accuracy: 0.9128\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2578 - accuracy: 0.9018\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2578 - accuracy: 0.8921\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2547 - accuracy: 0.9020\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2575 - accuracy: 0.8953\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2375 - accuracy: 0.9003\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2462 - accuracy: 0.9010\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2680 - accuracy: 0.8926\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2257 - accuracy: 0.9138\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2746 - accuracy: 0.8942\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8839\n",
            "Epoch 1/200\n",
            "17/17 [==============================] - 1s 8ms/step - loss: 1.5392 - accuracy: 0.5230\n",
            "Epoch 2/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.8658 - accuracy: 0.7948\n",
            "Epoch 3/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.6841 - accuracy: 0.7527\n",
            "Epoch 4/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8822\n",
            "Epoch 5/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.3433 - accuracy: 0.8880\n",
            "Epoch 6/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2757 - accuracy: 0.8972\n",
            "Epoch 7/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.2241 - accuracy: 0.9292\n",
            "Epoch 8/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2704 - accuracy: 0.9085\n",
            "Epoch 9/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1993 - accuracy: 0.9354\n",
            "Epoch 10/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1900 - accuracy: 0.9391\n",
            "Epoch 11/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2130 - accuracy: 0.9250\n",
            "Epoch 12/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1834 - accuracy: 0.9295\n",
            "Epoch 13/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1604 - accuracy: 0.9403\n",
            "Epoch 14/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1455 - accuracy: 0.9430\n",
            "Epoch 15/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.9336\n",
            "Epoch 16/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1415 - accuracy: 0.9517\n",
            "Epoch 17/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1659 - accuracy: 0.9525\n",
            "Epoch 18/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9321\n",
            "Epoch 19/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1457 - accuracy: 0.9418\n",
            "Epoch 20/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1485 - accuracy: 0.9290\n",
            "Epoch 21/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2118 - accuracy: 0.9138\n",
            "Epoch 22/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.9388\n",
            "Epoch 23/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1476 - accuracy: 0.9434\n",
            "Epoch 24/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1506 - accuracy: 0.9299\n",
            "Epoch 25/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1668 - accuracy: 0.9398\n",
            "Epoch 26/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1448 - accuracy: 0.9485\n",
            "Epoch 27/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1608 - accuracy: 0.9433\n",
            "Epoch 28/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1898 - accuracy: 0.9113\n",
            "Epoch 29/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.2837 - accuracy: 0.9169\n",
            "Epoch 30/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1827 - accuracy: 0.9239\n",
            "Epoch 31/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1883 - accuracy: 0.9161\n",
            "Epoch 32/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1641 - accuracy: 0.9270\n",
            "Epoch 33/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1629 - accuracy: 0.9258\n",
            "Epoch 34/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1223 - accuracy: 0.9440\n",
            "Epoch 35/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1309 - accuracy: 0.9470\n",
            "Epoch 36/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1199 - accuracy: 0.9565\n",
            "Epoch 37/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1511 - accuracy: 0.9386\n",
            "Epoch 38/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1430 - accuracy: 0.9409\n",
            "Epoch 39/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1295 - accuracy: 0.9538\n",
            "Epoch 40/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1332 - accuracy: 0.9455\n",
            "Epoch 41/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1696 - accuracy: 0.9313\n",
            "Epoch 42/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1644 - accuracy: 0.9308\n",
            "Epoch 43/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1432 - accuracy: 0.9390\n",
            "Epoch 44/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1084 - accuracy: 0.9646\n",
            "Epoch 45/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9521\n",
            "Epoch 46/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1306 - accuracy: 0.9407\n",
            "Epoch 47/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1383 - accuracy: 0.9453\n",
            "Epoch 48/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1308 - accuracy: 0.9421\n",
            "Epoch 49/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1513 - accuracy: 0.9404\n",
            "Epoch 50/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9284\n",
            "Epoch 51/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 0.9265\n",
            "Epoch 52/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1388 - accuracy: 0.9325\n",
            "Epoch 53/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1125 - accuracy: 0.9503\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1129 - accuracy: 0.9589\n",
            "Epoch 55/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1304 - accuracy: 0.9439\n",
            "Epoch 56/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0920 - accuracy: 0.9575\n",
            "Epoch 57/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.9149\n",
            "Epoch 58/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1312 - accuracy: 0.9430\n",
            "Epoch 59/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1124 - accuracy: 0.9527\n",
            "Epoch 60/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1117 - accuracy: 0.9543\n",
            "Epoch 61/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1007 - accuracy: 0.9416\n",
            "Epoch 62/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1093 - accuracy: 0.9412\n",
            "Epoch 63/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1106 - accuracy: 0.9408\n",
            "Epoch 64/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9565\n",
            "Epoch 65/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1141 - accuracy: 0.9469\n",
            "Epoch 66/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1371 - accuracy: 0.9479\n",
            "Epoch 67/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1034 - accuracy: 0.9461\n",
            "Epoch 68/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9474\n",
            "Epoch 69/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1080 - accuracy: 0.9569\n",
            "Epoch 70/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1028 - accuracy: 0.9633\n",
            "Epoch 71/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1063 - accuracy: 0.9470\n",
            "Epoch 72/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1093 - accuracy: 0.9436\n",
            "Epoch 73/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1095 - accuracy: 0.9447\n",
            "Epoch 74/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.9379\n",
            "Epoch 75/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1121 - accuracy: 0.9325\n",
            "Epoch 76/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1239 - accuracy: 0.9472\n",
            "Epoch 77/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1273 - accuracy: 0.9372\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1057 - accuracy: 0.9482\n",
            "Epoch 79/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1158 - accuracy: 0.9564\n",
            "Epoch 80/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1418 - accuracy: 0.9181\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1292 - accuracy: 0.9390\n",
            "Epoch 82/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0910 - accuracy: 0.9648\n",
            "Epoch 83/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1152 - accuracy: 0.9455\n",
            "Epoch 84/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1274 - accuracy: 0.9394\n",
            "Epoch 85/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1277 - accuracy: 0.9367\n",
            "Epoch 86/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1448 - accuracy: 0.9426\n",
            "Epoch 87/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1351 - accuracy: 0.9342\n",
            "Epoch 88/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1376 - accuracy: 0.9307\n",
            "Epoch 89/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0952 - accuracy: 0.9584\n",
            "Epoch 90/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1238 - accuracy: 0.9383\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1288 - accuracy: 0.9487\n",
            "Epoch 92/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1139 - accuracy: 0.9411\n",
            "Epoch 93/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1166 - accuracy: 0.9316\n",
            "Epoch 94/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1168 - accuracy: 0.9527\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1101 - accuracy: 0.9525\n",
            "Epoch 96/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1034 - accuracy: 0.9457\n",
            "Epoch 97/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1102 - accuracy: 0.9571\n",
            "Epoch 98/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1179 - accuracy: 0.9416\n",
            "Epoch 99/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0971 - accuracy: 0.9543\n",
            "Epoch 100/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1143 - accuracy: 0.9436\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1113 - accuracy: 0.9509\n",
            "Epoch 102/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 0.9315\n",
            "Epoch 103/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1327 - accuracy: 0.9391\n",
            "Epoch 104/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9680\n",
            "Epoch 105/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1325 - accuracy: 0.9287\n",
            "Epoch 106/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1326 - accuracy: 0.9415\n",
            "Epoch 107/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1342 - accuracy: 0.9349\n",
            "Epoch 108/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1076 - accuracy: 0.9523\n",
            "Epoch 109/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0970 - accuracy: 0.9480\n",
            "Epoch 110/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0955 - accuracy: 0.9657\n",
            "Epoch 111/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1175 - accuracy: 0.9505\n",
            "Epoch 112/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1161 - accuracy: 0.9442\n",
            "Epoch 113/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1353 - accuracy: 0.9284\n",
            "Epoch 114/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9435\n",
            "Epoch 115/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1024 - accuracy: 0.9493\n",
            "Epoch 116/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1010 - accuracy: 0.9558\n",
            "Epoch 117/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1421 - accuracy: 0.9401\n",
            "Epoch 118/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0893 - accuracy: 0.9662\n",
            "Epoch 119/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.9364\n",
            "Epoch 120/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1289 - accuracy: 0.9464\n",
            "Epoch 121/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1169 - accuracy: 0.9505\n",
            "Epoch 122/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1276 - accuracy: 0.9465\n",
            "Epoch 123/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1307 - accuracy: 0.9371\n",
            "Epoch 124/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.9483\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9470\n",
            "Epoch 126/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1016 - accuracy: 0.9513\n",
            "Epoch 127/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1503 - accuracy: 0.9270\n",
            "Epoch 128/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1347 - accuracy: 0.9242\n",
            "Epoch 129/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1284 - accuracy: 0.9480\n",
            "Epoch 130/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1162 - accuracy: 0.9464\n",
            "Epoch 131/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1088 - accuracy: 0.9485\n",
            "Epoch 132/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1181 - accuracy: 0.9557\n",
            "Epoch 133/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1369 - accuracy: 0.9249\n",
            "Epoch 134/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1314 - accuracy: 0.9181\n",
            "Epoch 135/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1182 - accuracy: 0.9498\n",
            "Epoch 136/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1123 - accuracy: 0.9464\n",
            "Epoch 137/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1058 - accuracy: 0.9542\n",
            "Epoch 138/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1275 - accuracy: 0.9319\n",
            "Epoch 139/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1241 - accuracy: 0.9483\n",
            "Epoch 140/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.9426\n",
            "Epoch 141/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0960 - accuracy: 0.9484\n",
            "Epoch 142/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1261 - accuracy: 0.9364\n",
            "Epoch 143/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1493 - accuracy: 0.9149\n",
            "Epoch 144/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0981 - accuracy: 0.9498\n",
            "Epoch 145/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1311 - accuracy: 0.9364\n",
            "Epoch 146/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1204 - accuracy: 0.9437\n",
            "Epoch 147/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1153 - accuracy: 0.9476\n",
            "Epoch 148/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0948 - accuracy: 0.9519\n",
            "Epoch 149/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1296 - accuracy: 0.9314\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0844 - accuracy: 0.9701\n",
            "Epoch 151/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.9260\n",
            "Epoch 152/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1142 - accuracy: 0.9400\n",
            "Epoch 153/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9488\n",
            "Epoch 154/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1143 - accuracy: 0.9616\n",
            "Epoch 155/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9434\n",
            "Epoch 156/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1508 - accuracy: 0.9172\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1151 - accuracy: 0.9478\n",
            "Epoch 158/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1353 - accuracy: 0.9343\n",
            "Epoch 159/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1374 - accuracy: 0.9392\n",
            "Epoch 160/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1113 - accuracy: 0.9488\n",
            "Epoch 161/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0957 - accuracy: 0.9580\n",
            "Epoch 162/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1126 - accuracy: 0.9529\n",
            "Epoch 163/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1178 - accuracy: 0.9474\n",
            "Epoch 164/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1175 - accuracy: 0.9439\n",
            "Epoch 165/200\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1132 - accuracy: 0.9340\n",
            "Epoch 166/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1368 - accuracy: 0.9354\n",
            "Epoch 167/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1221 - accuracy: 0.9498\n",
            "Epoch 168/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1149 - accuracy: 0.9484\n",
            "Epoch 169/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1317 - accuracy: 0.9411\n",
            "Epoch 170/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.9581\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1242 - accuracy: 0.9370\n",
            "Epoch 172/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1012 - accuracy: 0.9523\n",
            "Epoch 173/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1041 - accuracy: 0.9609\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1305 - accuracy: 0.9385\n",
            "Epoch 175/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1257 - accuracy: 0.9457\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0909 - accuracy: 0.9592\n",
            "Epoch 177/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1237 - accuracy: 0.9413\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1056 - accuracy: 0.9531\n",
            "Epoch 179/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.9284\n",
            "Epoch 180/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1051 - accuracy: 0.9428\n",
            "Epoch 181/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1060 - accuracy: 0.9544\n",
            "Epoch 182/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0981 - accuracy: 0.9526\n",
            "Epoch 183/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1164 - accuracy: 0.9412\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1242 - accuracy: 0.9500\n",
            "Epoch 185/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1025 - accuracy: 0.9478\n",
            "Epoch 186/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1260 - accuracy: 0.9409\n",
            "Epoch 187/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1213 - accuracy: 0.9362\n",
            "Epoch 188/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1606 - accuracy: 0.9269\n",
            "Epoch 189/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.9531\n",
            "Epoch 190/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1395 - accuracy: 0.9255\n",
            "Epoch 191/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1304 - accuracy: 0.9421\n",
            "Epoch 192/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1204 - accuracy: 0.9398\n",
            "Epoch 193/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.9436\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 0.9458\n",
            "Epoch 195/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0988 - accuracy: 0.9559\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1177 - accuracy: 0.9389\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1368 - accuracy: 0.9452\n",
            "Epoch 198/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1209 - accuracy: 0.9437\n",
            "Epoch 199/200\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.1251 - accuracy: 0.9442\n",
            "Epoch 200/200\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1411 - accuracy: 0.9170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhKZIK81ND8g"
      },
      "source": [
        "### 5.2 Testing Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEOgMCkuNDj7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c80Fy6oGPr5",
        "outputId": "648088cf-ce1f-489e-b571-793a4bcaf224"
      },
      "source": [
        "for i in range(4):\n",
        "    loss, accuracy = models[i].evaluate(X_test, one_hot(y_test[:,i], tag_counts[i]), verbose=0)\n",
        "\n",
        "    print(f'Model {i+1} loss: {loss:.5}')\n",
        "    print(f'Model {i+1} accuracy: {accuracy:.5}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1 loss: 9.447\n",
            "Model 1 accuracy: 0.66234\n",
            "Model 2 loss: 9.9406\n",
            "Model 2 accuracy: 0.35065\n",
            "Model 3 loss: 12.438\n",
            "Model 3 accuracy: 0.25974\n",
            "Model 4 loss: 9.6024\n",
            "Model 4 accuracy: 0.55844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ3BNe8O4Zul",
        "outputId": "e67f98f8-8ddb-4e22-a66b-c43a45295072"
      },
      "source": [
        "results = sector_model.predict(X_test)\n",
        "results = np.argmax(results, axis=1)\n",
        "\n",
        "for i in range(len(results)):\n",
        "    print(f'Expected: {y_test[i,0]} Got: {results[i]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected: 1 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 1 Got: 1\n",
            "Expected: 1 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 5 Got: 1\n",
            "Expected: 1 Got: 1\n",
            "Expected: 1 Got: 1\n",
            "Expected: 3 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 6 Got: 6\n",
            "Expected: 4 Got: 3\n",
            "Expected: 1 Got: 1\n",
            "Expected: 2 Got: 1\n",
            "Expected: 2 Got: 4\n",
            "Expected: 4 Got: 6\n",
            "Expected: 4 Got: 6\n",
            "Expected: 1 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 1 Got: 1\n",
            "Expected: 2 Got: 3\n",
            "Expected: 1 Got: 3\n",
            "Expected: 1 Got: 1\n",
            "Expected: 3 Got: 3\n",
            "Expected: 6 Got: 6\n",
            "Expected: 4 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 3 Got: 4\n",
            "Expected: 1 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 3 Got: 3\n",
            "Expected: 0 Got: 6\n",
            "Expected: 3 Got: 6\n",
            "Expected: 4 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 1 Got: 6\n",
            "Expected: 1 Got: 1\n",
            "Expected: 4 Got: 6\n",
            "Expected: 6 Got: 6\n",
            "Expected: 6 Got: 6\n",
            "Expected: 6 Got: 6\n",
            "Expected: 6 Got: 1\n",
            "Expected: 2 Got: 2\n",
            "Expected: 1 Got: 6\n",
            "Expected: 4 Got: 1\n",
            "Expected: 6 Got: 1\n",
            "Expected: 1 Got: 6\n",
            "Expected: 6 Got: 6\n",
            "Expected: 1 Got: 1\n",
            "Expected: 1 Got: 3\n",
            "Expected: 1 Got: 1\n",
            "Expected: 1 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 3 Got: 3\n",
            "Expected: 1 Got: 1\n",
            "Expected: 1 Got: 1\n",
            "Expected: 1 Got: 1\n",
            "Expected: 1 Got: 1\n",
            "Expected: 0 Got: 6\n",
            "Expected: 1 Got: 1\n",
            "Expected: 1 Got: 1\n",
            "Expected: 1 Got: 1\n",
            "Expected: 6 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 4 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 1 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 1 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 1 Got: 1\n",
            "Expected: 4 Got: 1\n",
            "Expected: 5 Got: 1\n",
            "Expected: 6 Got: 6\n",
            "Expected: 6 Got: 6\n",
            "Expected: 4 Got: 1\n",
            "Expected: 6 Got: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aarHE3sNuN1"
      },
      "source": [
        "### 5.3. Saving Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vd4RJP0NxVB",
        "outputId": "5ce21237-9abf-49ca-e404-cb22c382160d"
      },
      "source": [
        "# save models to file\n",
        "for i in range(4):\n",
        "    models[i].save(f'./model_{i+1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./model_1/assets\n",
            "INFO:tensorflow:Assets written to: ./model_2/assets\n",
            "INFO:tensorflow:Assets written to: ./model_3/assets\n",
            "INFO:tensorflow:Assets written to: ./model_4/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-frVyS9_OqM5",
        "outputId": "7f0d3734-8bfd-46e0-a390-8c57de8aceb2"
      },
      "source": [
        "!zip -r model_4.zip ./model_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model_4/ (stored 0%)\n",
            "  adding: model_4/saved_model.pb (deflated 89%)\n",
            "  adding: model_4/variables/ (stored 0%)\n",
            "  adding: model_4/variables/variables.index (deflated 66%)\n",
            "  adding: model_4/variables/variables.data-00000-of-00001 (deflated 43%)\n",
            "  adding: model_4/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vcPrnMEK8tR"
      },
      "source": [
        "---\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u_5izYH3HNX"
      },
      "source": [
        "## Testing(BoW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE_VnilXOAhK",
        "outputId": "8dbd1dff-9a0f-4311-ba5b-ce24af2ddd46"
      },
      "source": [
        "for token in processed_doc[21]:\n",
        "    print(token.text, token.ent_type_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPZTP ORG\n",
            "FAMILY \n",
            "is \n",
            "an \n",
            "ACRA-registered \n",
            "entity \n",
            "that \n",
            "has \n",
            "been \n",
            "operating \n",
            "for \n",
            "14 DATE\n",
            "years DATE\n",
            "7 DATE\n",
            "months DATE\n",
            "in \n",
            "Singapore GPE\n",
            "since \n",
            "its \n",
            "incorporation \n",
            "y \n",
            "in \n",
            "2006 DATE\n",
            ". \n",
            "Officially \n",
            ", \n",
            "TPZTP ORG\n",
            "FAMILY ORG\n",
            "PTE ORG\n",
            ". ORG\n",
            "LTD \n",
            ". \n",
            "is \n",
            "registered \n",
            "as \n",
            "Exempt ORG\n",
            "Private ORG\n",
            "Limited ORG\n",
            "Company ORG\n",
            "with \n",
            "its \n",
            "address \n",
            "in \n",
            "District \n",
            "15 \n",
            "( \n",
            "Katong ORG\n",
            ", ORG\n",
            "Joo ORG\n",
            "Chiat ORG\n",
            ", \n",
            "Amber ORG\n",
            "Road ORG\n",
            ") \n",
            ", \n",
            "primarily \n",
            "operates \n",
            "in \n",
            "the \n",
            "sector \n",
            "of \n",
            "\" \n",
            "WHOLESALE \n",
            "OF \n",
            "HOUSEHOLD \n",
            "ELECTRICAL \n",
            "APPLIANCES \n",
            "AND \n",
            "EQUIPMENT \n",
            "( \n",
            "INCLUDING \n",
            "HOUSEHOLD \n",
            "AIR-CONDITIONERS \n",
            ") \n",
            "\" \n",
            ", \n",
            "SSIC ORG\n",
            "code \n",
            "- \n",
            "46435 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOA3hrpUna-I"
      },
      "source": [
        "### 4.6. Extracting random 100 from the 300 subsample to see quality of tokenization and lemmenization.\n",
        "\n",
        "---\n",
        "\n",
        "We will now extract some of the dataset from the 300 subsample dataset to examine the quality of the lemmenization process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ttThdvwnaOk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQUYiYqknq-7"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N9HIyG9nq6A"
      },
      "source": [
        "# 5.Further Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV6EiGilnurE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbZZCbdHv3ME"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hKvKHV38ly_"
      },
      "source": [
        "# 10.References\n",
        "\n",
        "\n",
        "## Linking GitHub Private Repo with Google Colab\n",
        "---\n",
        "1. [How to clone private Github repo from Google Colab using SSH](https://medium.com/@purba0101/how-to-clone-private-github-repo-in-google-colab-using-ssh-77384cfef18f)\n",
        "2. [Adding a new SSH key to your GitHub account](https://docs.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account)\n",
        "\n",
        "\n",
        "## How to classify text with NLTK\n",
        "---\n",
        "1. [Learning to Classify Text](https://www.nltk.org/book/ch06.html)\n",
        "\n",
        "\n",
        "## Other references\n",
        "---\n",
        "1. [Print very long string completely in pandas dataframe](https://stackoverflow.com/questions/29902714/print-very-long-string-completely-in-pandas-dataframe)\n",
        "2. [Removing newlines from messy strings in pandas dataframe cells?\n",
        "](https://stackoverflow.com/questions/44227748/removing-newlines-from-messy-strings-in-pandas-dataframe-cells)\n",
        "3. [Tokenizing using Pandas and spaCy](https://stackoverflow.com/questions/46981137/tokenizing-using-pandas-and-spacy)\n",
        "4. [Intro to NLP with spaCy](https://nicschrading.com/project/Intro-to-NLP-with-spaCy/)\n",
        "5. [A short introduction to NLP in Python with spaCy](https://towardsdatascience.com/a-short-introduction-to-nlp-in-python-with-spacy-d0aa819af3ad)\n",
        "6. [Punctuation, stopwords and lemmatization with spacy](https://stackoverflow.com/questions/57747613/punctuation-stopwords-and-lemmatization-with-spacy)\n",
        "\n"
      ]
    }
  ]
}